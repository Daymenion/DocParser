version: '3.8'

services:
  doc-parser-vllm:
    image: doc-parser:vllm
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: doc-parser-vllm
    restart: unless-stopped
    # Enable NVIDIA GPUs for legacy docker-compose setups (compose v1) or when --gpus is unavailable.
    # If your docker compose supports the 'gpus:' key, you can use that instead of 'runtime'.
    runtime: nvidia
    ports:
      - "9998:9998"
    environment:
      PYTHONPATH: /workspace/weights
      # Optional NVIDIA hints (Compose sets these automatically for most setups)
      NVIDIA_VISIBLE_DEVICES: all
      NVIDIA_DRIVER_CAPABILITIES: compute,utility
      # Enable verbose logging if device detection fails
      VLLM_LOGGING_LEVEL: INFO
    volumes:
      - ../weights/DotsOCR:/workspace/weights/DotsOCR
    entrypoint: ["vllm"]
    command: [
      "serve", "/workspace/weights/DotsOCR",
      "--host", "0.0.0.0",
      "--port", "9998",
      "--device", "cuda",
      "--dtype", "auto",
      "--tensor-parallel-size", "1",
      "--gpu-memory-utilization", "0.55",
      "--chat-template-content-format", "string",
      "--served-model-name", "model",
      "--trust-remote-code"
    ]

  doc-parser-app:
    image: doc-parser:app
    build:
      context: ..
      dockerfile: docker/Dockerfile.app
    container_name: doc-parser-app
    restart: unless-stopped
    depends_on:
      - doc-parser-vllm
    environment:
      APP_PORT: "7860"
      VLLM_HOST: doc-parser-vllm
      VLLM_PORT: "9998"
    ports:
      - "7860:7860"




