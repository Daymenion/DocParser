version: '3.8'

services:
  doc-parser-vllm:
    image: doc-parser:vllm
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: doc-parser-vllm
    restart: unless-stopped
    # Request NVIDIA GPUs via Compose (works with docker compose, not swarm)
    # To pin a specific GPU, run with: docker compose --profile gpu (and adjust as needed),
    # or override at runtime. For broad compatibility, default to all GPUs here.
    gpus: all
    ports:
      - "9998:8000"
    environment:
      PYTHONPATH: /workspace/weights
      # Optional NVIDIA hints (Compose sets these automatically for most setups)
      CUDA_VISIBLE_DEVICES: "1"
      NVIDIA_VISIBLE_DEVICES: "1"
      NVIDIA_DRIVER_CAPABILITIES: compute,utility
    volumes:
      - ../weights/DotsOCR:/workspace/weights/DotsOCR
    entrypoint: ["vllm"]
    command: [
      "serve", "/workspace/weights/DotsOCR",
      "--host", "0.0.0.0",
      "--port", "8000",
      "--dtype", "auto",
      "--tensor-parallel-size", "1",
      "--gpu-memory-utilization", "0.55",
      "--chat-template-content-format", "string",
      "--served-model-name", "model",
      "--trust-remote-code"
    ]

  doc-parser-app:
    image: doc-parser:app
    build:
      context: ..
      dockerfile: docker/Dockerfile.app
    container_name: doc-parser-app
    restart: unless-stopped
    depends_on:
      - doc-parser-vllm
    environment:
      APP_PORT: "7860"
      VLLM_HOST: doc-parser-vllm
      VLLM_PORT: "8000"
    ports:
      - "7860:7860"




