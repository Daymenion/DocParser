version: '3.8'

services:
  doc-parser-vllm:
    image: doc-parser:vllm
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: doc-parser-vllm
    restart: unless-stopped
    ports:
      - "9998:8000"
    environment:
      PYTHONPATH: /workspace/weights
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
              device_ids: ['1']
    volumes:
      - ../weights/DotsOCR:/workspace/weights/DotsOCR
    entrypoint: ["/bin/bash", "-lc"]
    command: |
      set -e
      echo "--- Starting vLLM server (doc-parser) ---"
      echo "PYTHONPATH=$PYTHONPATH"
      ls -la /workspace/weights/DotsOCR || true
      python -c "import DotsOCR.modeling_dots_ocr_vllm" || true
      exec vllm serve /workspace/weights/DotsOCR \
        --tensor-parallel-size 1 \
        --gpu-memory-utilization 0.55 \
        --chat-template-content-format string \
        --served-model-name model \
        --trust-remote-code

  doc-parser-app:
    image: doc-parser:app
    build:
      context: ..
      dockerfile: docker/Dockerfile.app
    container_name: doc-parser-app
    restart: unless-stopped
    depends_on:
      - doc-parser-vllm
    environment:
      APP_PORT: "7860"
      VLLM_HOST: doc-parser-vllm
      VLLM_PORT: "8000"
    ports:
      - "7860:7860"




